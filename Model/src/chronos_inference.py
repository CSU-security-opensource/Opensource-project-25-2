import pandas as pd
import numpy as np
from chronos import BaseChronosPipeline
from sklearn.metrics import mean_absolute_error, mean_squared_error, r2_score
import matplotlib.pyplot as plt
import time
import warnings
import torch

warnings.filterwarnings('ignore')
try:
    import matplotlib.font_manager as fm
    font_list = [f.name for f in fm.fontManager.ttflist]
    if 'NanumGothic' in font_list:
        plt.rcParams['font.family'] = 'NanumGothic'
    elif 'Malgun Gothic' in font_list:
        plt.rcParams['font.family'] = 'Malgun Gothic'
    else:
        # í•œê¸€ í°íŠ¸ê°€ ì—†ìœ¼ë©´ ê¹¨ì§ ë°©ì§€ë¥¼ ìœ„í•´ ì˜ì–´ í°íŠ¸ ì„¤ì •
        plt.rcParams['font.family'] = 'DejaVu Sans' 
except:
    pass

plt.rcParams['axes.unicode_minus'] = False


print("="*70)
print("ğŸŒ ì œì£¼ íƒœì–‘ê´‘ ë°œì „ ì˜ˆì¸¡ (Chronos Base - Context ìˆ˜ì •ë²„ì „)")
print("="*70)

# ========================================
# 1. ëª¨ë¸ ì„ íƒ ë° ë¡œë“œ
# ========================================
print("\nğŸ“¦ Chronos ëª¨ë¸ ë¡œë”© ì¤‘...")

# GPU ì‚¬ìš© ê°€ëŠ¥ ì—¬ë¶€ í™•ì¸
device_map = "cuda" if torch.cuda.is_available() else "cpu"
print(f"   Using device: {device_map.upper()}")

model_name = 'amazon/chronos-t5-large' 

start_time = time.time()

try:
    pipeline = BaseChronosPipeline.from_pretrained(
        model_name, 
        device_map=device_map,
        torch_dtype=torch.bfloat16 if device_map == "cuda" else torch.float32
    )
    load_time = time.time() - start_time
    print(f"âœ… ëª¨ë¸ ë¡œë“œ ì™„ë£Œ! (ì†Œìš”: {load_time:.1f}ì´ˆ)\n")
    
except Exception as e:
    print(f"âŒ ëª¨ë¸ ë¡œë“œ ì‹¤íŒ¨: {e}")
    exit()

# ========================================
# 2. ë°ì´í„° ë¡œë“œ
# ========================================
print("ğŸ“‚ ë°ì´í„° ë¡œë”© ì¤‘...")

try:
    train_df = pd.read_csv("../train_data_fixed.csv")
    val_df = pd.read_csv("../validation_data_fixed.csv")
    test_df = pd.read_csv("../test_data_fixed.csv")
    
    # datetime ë³€í™˜
    train_df['timestamp'] = pd.to_datetime(train_df['timestamp'])
    val_df['timestamp'] = pd.to_datetime(val_df['timestamp'])
    test_df['timestamp'] = pd.to_datetime(test_df['timestamp'])
    
    print("âœ… ëª¨ë“  ë°ì´í„° ë¡œë“œ ì™„ë£Œ!")
    
except FileNotFoundError as e:
    print(f"âŒ íŒŒì¼ ì—†ìŒ: {e}")
    exit()

# ========================================
# 3. Context ë°ì´í„° ì¤€ë¹„ (í•µì‹¬ ìˆ˜ì • ë¶€ë¶„)
# ========================================
print("\n" + "="*70)
print("ğŸ“ Context ë°ì´í„° ì¤€ë¹„ (Data Leakage ë°©ì§€ ë° ì—°ê²°)")
print("="*70)

# Validation ì˜ˆì¸¡ìš© Context (Trainë§Œ ì‚¬ìš©)
val_context_df = pd.DataFrame({
    'item_id': 'jeju_solar',
    'timestamp': train_df['timestamp'],
    'value': train_df['ì „ë ¥ìˆ˜ìš”ëŸ‰']
})

#  Test ì˜ˆì¸¡ìš© Context (Train + Validation í•©ë³¸ ì‚¬ìš©)
full_history_df = pd.concat([train_df, val_df]).sort_values('timestamp').reset_index(drop=True)

test_context_df = pd.DataFrame({
    'item_id': 'jeju_solar',
    'timestamp': full_history_df['timestamp'],
    'value': full_history_df['ì „ë ¥ìˆ˜ìš”ëŸ‰']
})

print(f"âœ… Context ì¤€ë¹„ ì™„ë£Œ:")
print(f"  1. Validation ì˜ˆì¸¡ìš© (Train Only): {len(val_context_df):,}ê°œ (ë: {val_context_df['timestamp'].max()})")
print(f"  2. Test ì˜ˆì¸¡ìš© (Train + Val):      {len(test_context_df):,}ê°œ (ë: {test_context_df['timestamp'].max()})")
print(f"     -> Test ë°ì´í„° ì‹œì‘ì ì¸ {test_df['timestamp'].min()}ê³¼ ì—°ê²°ë¨.")


# ========================================
# 4. Validation ì˜ˆì¸¡
# ========================================
print("\n" + "="*70)
print("ğŸ” Validation ë°ì´í„° ì˜ˆì¸¡")
print("="*70)

val_len = len(val_df)
print(f"ì˜ˆì¸¡ ê¸¸ì´: {val_len:,}ê°œ ì‹œê°„")

try:
    val_pred_df = pipeline.predict_df(
        val_context_df, # Train ë°ì´í„°ë§Œ ë³´ê³  ì˜ˆì¸¡
        prediction_length=val_len,
        quantile_levels=[0.1, 0.5, 0.9],
        id_column="item_id",
        timestamp_column="timestamp",
        target="value",
    )
    
    # ìŒìˆ˜ê°’ ë³´ì • (Post-processing)
    cols = ['0.1', '0.5', '0.9']
    val_pred_df[cols] = val_pred_df[cols].clip(lower=0)
    
    # í‰ê°€
    y_val_true = val_df['ì „ë ¥ìˆ˜ìš”ëŸ‰'].values
    y_val_pred = val_pred_df['0.5'].values[:len(y_val_true)]
    
    val_mae = mean_absolute_error(y_val_true, y_val_pred)
    val_r2 = r2_score(y_val_true, y_val_pred)
    
    print(f"ğŸ“Š Validation ê²°ê³¼:")
    print(f"  - MAE: {val_mae:.2f} MWh")
    print(f"  - RÂ²:  {val_r2:.4f}")
    
except Exception as e:
    print(f"âš ï¸ Validation ì˜ˆì¸¡ ì¤‘ ì—ëŸ¬: {e}")


# ========================================
# 5. Test ë°ì´í„° ì˜ˆì¸¡ (ìµœì¢… í‰ê°€)
# ========================================
print("\n" + "="*70)
print("ğŸ§ª Test ë°ì´í„° ì˜ˆì¸¡ (ìµœì¢… í‰ê°€)")
print("="*70)

test_len = len(test_df)
print(f"ì˜ˆì¸¡ ê¸¸ì´: {test_len:,}ê°œ ì‹œê°„")
print(f"ì‹œì‘ ì‹œê°: {pd.Timestamp.now().strftime('%H:%M:%S')}")

test_start = time.time()

try:
    # test_context_df ì‚¬ìš© (Train+Val ë°ì´í„°)
    test_pred_df = pipeline.predict_df(
        test_context_df, 
        prediction_length=test_len,
        quantile_levels=[0.1, 0.5, 0.9],
        id_column="item_id",
        timestamp_column="timestamp",
        target="value",
    )
    
    # ìŒìˆ˜ê°’ ë³´ì • (Post-processing)
    cols = ['0.1', '0.5', '0.9']
    test_pred_df[cols] = test_pred_df[cols].clip(lower=0)

    test_time = time.time() - test_start
    print(f"âœ… Test ì˜ˆì¸¡ ì™„ë£Œ! (ì†Œìš”: {test_time/60:.1f}ë¶„)")

except Exception as e:
    print(f"âŒ Test ì˜ˆì¸¡ ì‹¤íŒ¨: {e}")
    exit()

# ========================================
# 6. Test ì„±ëŠ¥ í‰ê°€
# ========================================
y_test_true = test_df['ì „ë ¥ìˆ˜ìš”ëŸ‰'].values
y_test_pred = test_pred_df['0.5'].values[:len(y_test_true)]

# ë©”íŠ¸ë¦­ ê³„ì‚°
mae = mean_absolute_error(y_test_true, y_test_pred)
rmse = np.sqrt(mean_squared_error(y_test_true, y_test_pred))
r2 = r2_score(y_test_true, y_test_pred)

# ë‚® ì‹œê°„(06~18ì‹œ) ì„±ëŠ¥ ë³„ë„ ê³„ì‚°
hours = test_df['timestamp'].dt.hour.values
day_mask = (hours >= 6) & (hours <= 18)
day_mae = mean_absolute_error(y_test_true[day_mask], y_test_pred[day_mask])

print(f"\n{'='*70}")
print(f"ğŸ“Š ìµœì¢… ì„±ëŠ¥ í‰ê°€ ê²°ê³¼")
print(f"{'='*70}")
print(f"MAE (í‰ê·  ì ˆëŒ€ ì˜¤ì°¨):    {mae:.3f} MWh")
print(f"RMSE (í‰ê·  ì œê³±ê·¼ ì˜¤ì°¨): {rmse:.3f} MWh")
print(f"RÂ² Score (ê²°ì •ê³„ìˆ˜):     {r2:.4f}")
print(f"ë‚® ì‹œê°„ MAE:             {day_mae:.3f} MWh")
print(f"í‰ê·  ì‹¤ì œ ë°œì „ëŸ‰:        {np.mean(y_test_true):.3f} MWh")
print(f"í‰ê·  ì˜ˆì¸¡ ë°œì „ëŸ‰:        {np.mean(y_test_pred):.3f} MWh")
print(f"{'='*70}\n")

# ========================================
# 7. ì‹œê°í™”
# ========================================
print("ğŸ“ˆ ì‹œê°í™” ìƒì„± ì¤‘...")

fig, axes = plt.subplots(3, 1, figsize=(20, 14))

# 1) ì „ì²´ ì‹œê³„ì—´
axes[0].plot(test_df['timestamp'], y_test_true, label='Actual', color='black', alpha=0.6, linewidth=1)
axes[0].plot(test_df['timestamp'], y_test_pred, label='Prediction (Chronos)', color='#007acc', alpha=0.8, linewidth=1)
axes[0].set_title(f'Test Whole Period (R2: {r2:.3f}, MAE: {mae:.2f})', fontsize=14)
axes[0].legend()
axes[0].grid(True, alpha=0.3)

# 2) í™•ëŒ€ (ì²« 14ì¼)
zoom_slice = slice(0, 24 * 14)
axes[1].plot(test_df['timestamp'][zoom_slice], y_test_true[zoom_slice], '.-', label='Actual', color='black')
axes[1].plot(test_df['timestamp'][zoom_slice], y_test_pred[zoom_slice], '.-', label='Prediction', color='#007acc')
axes[1].set_title('First 14 Days Zoom-in', fontsize=14)
axes[1].legend()
axes[1].grid(True, alpha=0.3)

# 3) ì‚°ì ë„
axes[2].scatter(y_test_true, y_test_pred, alpha=0.3, s=10, color='#007acc')
axes[2].plot([0, y_test_true.max()], [0, y_test_true.max()], 'r--', label='Perfect Fit')
axes[2].set_xlabel('Actual')
axes[2].set_ylabel('Predicted')
axes[2].set_title('Actual vs Predicted Scatter', fontsize=14)
axes[2].grid(True, alpha=0.3)

plt.tight_layout()
plt.savefig('../Results/Result_Fixed_Context.png')
print("ğŸ’¾ ê·¸ë˜í”„ ì €ì¥ ì™„ë£Œ: Result_Fixed_Context.png")

# CSV ì €ì¥
result_df = pd.DataFrame({
    'timestamp': test_df['timestamp'],
    'Actual': y_test_true,
    'Predicted': y_test_pred
})
result_df.to_csv("../Results/Result_Fixed_Context.csv", index=False)
print("ğŸ’¾ ê²°ê³¼ CSV ì €ì¥ ì™„ë£Œ: Result_Fixed_Context.csv")

print("\nâœ… ëª¨ë“  ì‘ì—… ì™„ë£Œ!")